{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries and functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T15:48:01.486364Z",
     "start_time": "2020-05-09T15:48:01.228845Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd.variable import Variable\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T15:48:01.489862Z",
     "start_time": "2020-05-09T15:48:01.487498Z"
    }
   },
   "outputs": [],
   "source": [
    "def underlined_text(text, char = '='):\n",
    "    length = len(text)\n",
    "    print(text)\n",
    "    for i in range(length):\n",
    "        print(char, end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T15:48:03.134368Z",
     "start_time": "2020-05-09T15:48:01.491075Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X\n",
      "=\n",
      "Shape =  torch.Size([10, 1])\n",
      "tensor([[0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4],\n",
      "        [5],\n",
      "        [6],\n",
      "        [7],\n",
      "        [8],\n",
      "        [9]], device='cuda:0')\n",
      "\n",
      "y\n",
      "=\n",
      "torch.Size([10])\n",
      "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 0], device='cuda:0')\n",
      "\n",
      "Sequence order: (Input => Output)\n",
      "=================================\n",
      "0 => 1\n",
      "1 => 2\n",
      "2 => 3\n",
      "3 => 4\n",
      "4 => 5\n",
      "5 => 6\n",
      "6 => 7\n",
      "7 => 8\n",
      "8 => 9\n",
      "9 => 0\n"
     ]
    }
   ],
   "source": [
    "underlined_text(\"X\")\n",
    "X = torch.tensor([[i] for i in range(0,10)]).to(device)\n",
    "print(\"Shape = \", X.shape)\n",
    "print(X)\n",
    "print()\n",
    "underlined_text(\"y\")\n",
    "y = torch.tensor([i for i in range(1,10)])\n",
    "z = torch.tensor([0])\n",
    "y = torch.cat((y, z), dim=0).to(device)\n",
    "print(y.shape)\n",
    "print(y)\n",
    "print()\n",
    "underlined_text(\"Sequence order: (Input => Output)\")\n",
    "for i in range(len(X)):\n",
    "    print(X[i].item(), '=>', y[i].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping dataX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshaping the dataX into a format [batch_size, seq_len, no_features]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T15:48:03.140043Z",
     "start_time": "2020-05-09T15:48:03.135725Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped X\n",
      "==========\n",
      "torch.Size([10, 1, 1])\n",
      "tensor([[[0]],\n",
      "\n",
      "        [[1]],\n",
      "\n",
      "        [[2]],\n",
      "\n",
      "        [[3]],\n",
      "\n",
      "        [[4]],\n",
      "\n",
      "        [[5]],\n",
      "\n",
      "        [[6]],\n",
      "\n",
      "        [[7]],\n",
      "\n",
      "        [[8]],\n",
      "\n",
      "        [[9]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "underlined_text(\"Reshaped X\")\n",
    "X = X.view(X.shape[0], 1, 1) # [batch_size, seq_len, features]\n",
    "print(X.shape)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T15:48:03.158408Z",
     "start_time": "2020-05-09T15:48:03.141065Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing X\n",
      "=============\n",
      "torch.Size([10, 1, 1])\n",
      "tensor([[[0.0000]],\n",
      "\n",
      "        [[0.1000]],\n",
      "\n",
      "        [[0.2000]],\n",
      "\n",
      "        [[0.3000]],\n",
      "\n",
      "        [[0.4000]],\n",
      "\n",
      "        [[0.5000]],\n",
      "\n",
      "        [[0.6000]],\n",
      "\n",
      "        [[0.7000]],\n",
      "\n",
      "        [[0.8000]],\n",
      "\n",
      "        [[0.9000]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "underlined_text(\"Normalizing X\")\n",
    "X = X/float(X.shape[0])\n",
    "print(X.shape)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the default mode (i.e. batch_first = False), the input shape should have the shape [seq_len, batch_size, \n",
    "features]. If you want the input shape should be of the shape [batch_size, seq_len, features], set batch_first = True.\n",
    "\n",
    "seq_len - Number of time steps in each input stream\n",
    "<br>\n",
    "features - Number of input features per time-step\n",
    "<br>\n",
    "batch_size - Size of the batches (sample size)\n",
    "<br>\n",
    "hidden_size - Number of RNN/LSTM blocks\n",
    "<br>\n",
    "num_layers - Number of hidden layers (default = 1)\n",
    "<br>\n",
    "<br>\n",
    "<u>Input shapes</u>\n",
    "<br>\n",
    "Input's shape = [seq_len, batch_size, features] if batch_first = False\n",
    "<br>\n",
    "Input's shape = [batch_size, seq_len, features] if batch_first = True\n",
    "<br>\n",
    "Initial hidden layer's shape = [num_layers, batch_size, hidden_size]\n",
    "<br>\n",
    "<br>\n",
    "<u>Hidden layer's shape</u>\n",
    "<br>\n",
    "[num_layers, batch_size, hidden_size]\n",
    "<br>\n",
    "\n",
    "<u>Output shape</u>\n",
    "<br>\n",
    "Hidden layer's shape = [num_layers, batch_size, hidden_size] (Since in an RNN, hidden state also returned as an output)\n",
    "<br>\n",
    "Output's shape = [seq_len, batch_size, hidden_size] if batch_first = False\n",
    "<br>\n",
    "Output's shape = [batch_size, seq_len, hidden_size] if batch_first = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNNDigit clsss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T15:48:03.386653Z",
     "start_time": "2020-05-09T15:48:03.159567Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNNDigit(\n",
      "  (rnn_layer): RNN(1, 32, num_layers=2, batch_first=True, dropout=0.3)\n",
      "  (linear_layer): Linear(in_features=32, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class RNNDigit(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, batch_size, num_layers, output_size):\n",
    "        super(RNNDigit, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.rnn_layer = nn.RNN(input_size=self.input_size, hidden_size=self.hidden_size,\n",
    "                               num_layers=self.num_layers, batch_first=True, dropout=0.3)\n",
    "        \n",
    "        self.linear_layer = nn.Linear(in_features=self.hidden_size, out_features=10)\n",
    "        \n",
    "        # Uncomment if needed to initialize hidden and cell states with random values\n",
    "        # self.hidden = self.init_hidden().to(device) # Initializing the hidden state\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        # Use this method, if needed to initialize the hidden states and cell states with random values\n",
    "        hidden_0 = Variable(torch.zeros(self.num_layers, self.batch_size, self.hidden_size))\n",
    "        return hidden_0\n",
    "        \n",
    "    def forward(self, x):\n",
    "        rnn_out, self.hidden = self.rnn_layer(x, None) # None says zero initial hidden and cell states\n",
    "        reshaped_rnn_out = rnn_out.view(self.batch_size, self.hidden_size)\n",
    "        final_out = self.linear_layer(reshaped_rnn_out)\n",
    "        return final_out\n",
    "        \n",
    "rnn = RNNDigit(input_size=1, hidden_size=32, batch_size=10, num_layers=2, output_size=10).to(device)\n",
    "print(rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T15:48:03.392122Z",
     "start_time": "2020-05-09T15:48:03.388584Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(rnn.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T15:48:03.401868Z",
     "start_time": "2020-05-09T15:48:03.395019Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_eval(preds, outputs):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    \n",
    "    max_vals, pred_class = torch.max(preds, dim=1)\n",
    "    for i in range(10):\n",
    "        if (pred_class[i]==outputs[i]):\n",
    "            correct += 1\n",
    "    acc = (correct/10.0)*100.0\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the loss.backward() function, the parameter 'retain_graph' needs to be set as 'True', since part of the computational graph will be freed during the execution of the loop. This is not needed in most cases, however, in an RNN, previous hidden states are passed to RNN cells, hence it needs the full graph to calculate the derivatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T15:48:15.302524Z",
     "start_time": "2020-05-09T15:48:03.404288Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loop\n",
      "=============\n",
      "Epoch:   100/5000 ==> Loss:  2.0938,  Accuracy:   20.00%\n",
      "Epoch:   200/5000 ==> Loss:  1.5306,  Accuracy:   40.00%\n",
      "Epoch:   300/5000 ==> Loss:  1.2720,  Accuracy:   50.00%\n",
      "Epoch:   400/5000 ==> Loss:  1.0482,  Accuracy:   80.00%\n",
      "Epoch:   500/5000 ==> Loss:  0.9512,  Accuracy:   70.00%\n",
      "Epoch:   600/5000 ==> Loss:  0.8325,  Accuracy:   80.00%\n",
      "Epoch:   700/5000 ==> Loss:  0.7561,  Accuracy:  100.00%\n",
      "Epoch:   800/5000 ==> Loss:  0.6593,  Accuracy:   80.00%\n",
      "Epoch:   900/5000 ==> Loss:  0.6652,  Accuracy:   80.00%\n",
      "Epoch:  1000/5000 ==> Loss:  0.6071,  Accuracy:   80.00%\n",
      "Epoch:  1100/5000 ==> Loss:  0.5166,  Accuracy:   80.00%\n",
      "Epoch:  1200/5000 ==> Loss:  0.4802,  Accuracy:  100.00%\n",
      "Epoch:  1300/5000 ==> Loss:  0.4399,  Accuracy:   90.00%\n",
      "Epoch:  1400/5000 ==> Loss:  0.3263,  Accuracy:  100.00%\n",
      "Epoch:  1500/5000 ==> Loss:  0.3339,  Accuracy:  100.00%\n",
      "Epoch:  1600/5000 ==> Loss:  0.2539,  Accuracy:  100.00%\n",
      "Epoch:  1700/5000 ==> Loss:  0.3066,  Accuracy:  100.00%\n",
      "Epoch:  1800/5000 ==> Loss:  0.2794,  Accuracy:  100.00%\n",
      "Epoch:  1900/5000 ==> Loss:  0.3728,  Accuracy:   90.00%\n",
      "Epoch:  2000/5000 ==> Loss:  0.2507,  Accuracy:   90.00%\n",
      "Epoch:  2100/5000 ==> Loss:  0.1801,  Accuracy:  100.00%\n",
      "Epoch:  2200/5000 ==> Loss:  0.1547,  Accuracy:  100.00%\n",
      "Epoch:  2300/5000 ==> Loss:  0.1825,  Accuracy:  100.00%\n",
      "Epoch:  2400/5000 ==> Loss:  0.1461,  Accuracy:  100.00%\n",
      "Epoch:  2500/5000 ==> Loss:  0.1228,  Accuracy:  100.00%\n",
      "Epoch:  2600/5000 ==> Loss:  0.1290,  Accuracy:  100.00%\n",
      "Epoch:  2700/5000 ==> Loss:  0.1507,  Accuracy:  100.00%\n",
      "Epoch:  2800/5000 ==> Loss:  0.1317,  Accuracy:  100.00%\n",
      "Epoch:  2900/5000 ==> Loss:  0.1907,  Accuracy:   90.00%\n",
      "Epoch:  3000/5000 ==> Loss:  0.0840,  Accuracy:  100.00%\n",
      "Epoch:  3100/5000 ==> Loss:  0.0584,  Accuracy:  100.00%\n",
      "Epoch:  3200/5000 ==> Loss:  0.0755,  Accuracy:  100.00%\n",
      "Epoch:  3300/5000 ==> Loss:  0.1702,  Accuracy:   90.00%\n",
      "Epoch:  3400/5000 ==> Loss:  0.0632,  Accuracy:  100.00%\n",
      "Epoch:  3500/5000 ==> Loss:  0.1775,  Accuracy:  100.00%\n",
      "Epoch:  3600/5000 ==> Loss:  0.1104,  Accuracy:  100.00%\n",
      "Epoch:  3700/5000 ==> Loss:  0.0428,  Accuracy:  100.00%\n",
      "Epoch:  3800/5000 ==> Loss:  0.0700,  Accuracy:  100.00%\n",
      "Epoch:  3900/5000 ==> Loss:  0.1288,  Accuracy:   90.00%\n",
      "Epoch:  4000/5000 ==> Loss:  0.0897,  Accuracy:  100.00%\n",
      "Epoch:  4100/5000 ==> Loss:  0.0528,  Accuracy:  100.00%\n",
      "Epoch:  4200/5000 ==> Loss:  0.0344,  Accuracy:  100.00%\n",
      "Epoch:  4300/5000 ==> Loss:  0.0816,  Accuracy:  100.00%\n",
      "Epoch:  4400/5000 ==> Loss:  0.0239,  Accuracy:  100.00%\n",
      "Epoch:  4500/5000 ==> Loss:  0.0281,  Accuracy:  100.00%\n",
      "Epoch:  4600/5000 ==> Loss:  0.0468,  Accuracy:  100.00%\n",
      "Epoch:  4700/5000 ==> Loss:  0.1205,  Accuracy:   90.00%\n",
      "Epoch:  4800/5000 ==> Loss:  0.0217,  Accuracy:  100.00%\n",
      "Epoch:  4900/5000 ==> Loss:  0.0349,  Accuracy:  100.00%\n",
      "Epoch:  5000/5000 ==> Loss:  0.0146,  Accuracy:  100.00%\n"
     ]
    }
   ],
   "source": [
    "underlined_text(\"Training loop\")\n",
    "epochs = 5000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = rnn(X)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    accuracy = model_eval(y_pred, y)\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    if ((epoch+1)%100 == 0):\n",
    "        print(\"Epoch: \", \"{:4d}/{:4d} ==>\".format(epoch+1,epochs), \n",
    "              \"Loss: \", \"{:6.4f}, \".format(loss.item()), \"Accuracy: \", \"{:6.2f}%\".format(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "374.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
