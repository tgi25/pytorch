{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Loading-required-modules\" data-toc-modified-id=\"Loading-required-modules-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Loading required modules</a></span></li><li><span><a href=\"#MNIST-digits-dataset\" data-toc-modified-id=\"MNIST-digits-dataset-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>MNIST digits dataset</a></span><ul class=\"toc-item\"><li><span><a href=\"#Downloading-MNIST-dataset\" data-toc-modified-id=\"Downloading-MNIST-dataset-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Downloading MNIST dataset</a></span></li><li><span><a href=\"#Iterating-though-dataset\" data-toc-modified-id=\"Iterating-though-dataset-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Iterating though dataset</a></span></li><li><span><a href=\"#Is-the-training-dataset-balanced?\" data-toc-modified-id=\"Is-the-training-dataset-balanced?-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Is the training dataset balanced?</a></span><ul class=\"toc-item\"><li><span><a href=\"#Computing-the-frequency-of-each-digit-in-the-training-dataset\" data-toc-modified-id=\"Computing-the-frequency-of-each-digit-in-the-training-dataset-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>Computing the frequency of each digit in the training dataset</a></span></li><li><span><a href=\"#Computing-the-percentages-of-each-digit-in-the-training-dataset\" data-toc-modified-id=\"Computing-the-percentages-of-each-digit-in-the-training-dataset-2.3.2\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>Computing the percentages of each digit in the training dataset</a></span></li></ul></li></ul></li><li><span><a href=\"#CFAR10-dataset\" data-toc-modified-id=\"CFAR10-dataset-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>CFAR10 dataset</a></span><ul class=\"toc-item\"><li><span><a href=\"#Downloading-CIFAR10-dataset\" data-toc-modified-id=\"Downloading-CIFAR10-dataset-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Downloading CIFAR10 dataset</a></span></li><li><span><a href=\"#Iterating-through-dataset\" data-toc-modified-id=\"Iterating-through-dataset-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Iterating through dataset</a></span></li><li><span><a href=\"#Changing-the-batch_size-and-shuffle\" data-toc-modified-id=\"Changing-the-batch_size-and-shuffle-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Changing the batch_size and shuffle</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T13:48:30.943950Z",
     "start_time": "2020-04-10T13:48:30.264712Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import matplotlib.pyplot as plt #To display images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST digits dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T13:52:49.917498Z",
     "start_time": "2020-04-10T13:52:49.900178Z"
    }
   },
   "outputs": [],
   "source": [
    "trainMNIST = datasets.MNIST(\"\",  #Folder where the dataset to be stored; empty means stored in current folder\n",
    "    train=True,  #Download the 'training' dataset, False => download 'test' dataset\n",
    "    download=True,  #Should be 'True' in the first time downling the dataset, else 'False'\n",
    "    transform=transforms.Compose([transforms.ToTensor()]))  #Transform the data to tensors\n",
    "testMNIST = datasets.MNIST(\n",
    "    \"\",  #Load from the current folder\n",
    "    train=False,  #Downloading/loading 'test' dataset\n",
    "    download=True,  #Downloading if it is not in the current folder\n",
    "    transform=transforms.Compose([transforms.ToTensor()]))  #Transform to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T13:54:41.154199Z",
     "start_time": "2020-04-10T13:54:41.148004Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size - Training dataset =  10\n",
      "Batch size - Test dataset     =  10\n"
     ]
    }
   ],
   "source": [
    "trainMNISTLoader = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "testMNISTLoader  = torch.utils.data.DataLoader(test,  batch_size=10, shuffle=True)\n",
    "\n",
    "print(\"Batch size - Training dataset = \", trainMNISTLoader.batch_size)\n",
    "print(\"Batch size - Test dataset     = \", testMNISTLoader.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterating though dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T13:54:54.954599Z",
     "start_time": "2020-04-10T13:54:54.939016Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([2, 8, 8, 7, 3, 1, 9, 2, 3, 6])]\n"
     ]
    }
   ],
   "source": [
    "for data in trainMNISTLoader:\n",
    "    print(data) #Prints the first batch\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T13:48:31.066811Z",
     "start_time": "2020-04-10T13:48:31.061140Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "tensor(7)\n"
     ]
    }
   ],
   "source": [
    "image1, label1 = data[0][0], data[1][0] #data[i][j] - i=0 => images, i=1 => labels; j = example number\n",
    "print(image1.shape) #1st dimension - no of channels, other two dimensions - image's height and width\n",
    "print(label1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T13:48:31.172933Z",
     "start_time": "2020-04-10T13:48:31.068987Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd47a122c10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image1.view(28,28)) #Reshaping the (1, 28, 28) matrix to (28,28) matrix that can be displayed by maxplotlib - Refer Lesson 02 - Tensor Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T13:48:31.176934Z",
     "start_time": "2020-04-10T13:48:31.174087Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([784])\n"
     ]
    }
   ],
   "source": [
    "new_image1 = image1.view(-1) #Flatten the image to a 1D tensor; in case vanilla neural network we can send the input as a 1D tensor\n",
    "print(new_image1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is the training dataset balanced?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the frequency of each digit in the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T13:48:35.011878Z",
     "start_time": "2020-04-10T13:48:31.178884Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of each digit =>  {0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n",
      "Total number of digits in the MNIST training dataset =  60000\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "count_dictionary = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, 9:0}\n",
    "\n",
    "for data in trainset: #Counting how many times each digit is in the training dataset\n",
    "    Xs, ys = data #Labels are in ys\n",
    "    for y in ys: #Iterate through each label (digit)\n",
    "        count_dictionary[int(y)] += 1\n",
    "        total += 1\n",
    "        \n",
    "print(\"Count of each digit => \", count_dictionary)\n",
    "print(\"Total number of digits in the MNIST training dataset = \", total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the percentages of each digit in the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T13:48:35.018461Z",
     "start_time": "2020-04-10T13:48:35.013130Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 =>   9.87 %\n",
      "1 =>  11.24 %\n",
      "2 =>   9.93 %\n",
      "3 =>  10.22 %\n",
      "4 =>   9.74 %\n",
      "5 =>   9.04 %\n",
      "6 =>   9.86 %\n",
      "7 =>  10.44 %\n",
      "8 =>   9.75 %\n",
      "9 =>   9.92 %\n"
     ]
    }
   ],
   "source": [
    "percentage_dictionary = {0:0.0, 1:0.0, 2:0.0, 3:0.0, 4:0.0, 5:0.0, 6:0.0, 7:0.0, 8:0.0, 9:0.0}\n",
    "\n",
    "for i in count_dictionary:\n",
    "    percentage_dictionary[i] = count_dictionary[i]/total * 100\n",
    "    print(i, \"=>\", \"{:6.2f}\".format(percentage_dictionary[i]), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CFAR10 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading CIFAR10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T13:48:35.742535Z",
     "start_time": "2020-04-10T13:48:35.019303Z"
    }
   },
   "outputs": [],
   "source": [
    "trainCFAR10 = datasets.CIFAR10(\"\",\n",
    "                               train=True,\n",
    "                               download=False,\n",
    "                               transform=transforms.Compose(\n",
    "                                   [transforms.ToTensor()]))\n",
    "\n",
    "testCFAR10 = datasets.CIFAR10(\"\",\n",
    "                               train=False,\n",
    "                               download=False,\n",
    "                               transform=transforms.Compose(\n",
    "                                   [transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T13:48:35.746257Z",
     "start_time": "2020-04-10T13:48:35.743517Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchvision.datasets.cifar.CIFAR10"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trainCFAR10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterating through dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T15:53:29.280313Z",
     "start_time": "2020-04-10T15:53:29.271348Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size - training dataset =  1\n",
      "Data iterator =  <torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7fd45fc1fe50>\n",
      "Size of images torch.Size([1, 3, 32, 32])\n",
      "Labels tensor =  tensor([6])\n",
      "Size of images torch.Size([1, 3, 32, 32])\n",
      "Labels tensor =  tensor([9])\n"
     ]
    }
   ],
   "source": [
    "trainCFAR10Loader = torch.utils.data.DataLoader(trainCFAR10)\n",
    "print(\"Batch size - training dataset = \", trainCFAR10Loader.batch_size)\n",
    "\n",
    "data_itr = iter(trainCFAR10Loader) #Creates a data iterator for trainCFAR10Loader\n",
    "print(\"Data iterator = \", data_itr)\n",
    "\n",
    "images, labels = data_itr.next() #Gets the first batch\n",
    "print(\"Size of images\", images.shape) #1 - batch size, 3 - no of chanells, last two dimensions - height and width of images\n",
    "print(\"Labels tensor = \", labels) #Only 1 label is in the tensor since the batch size is 1\n",
    "\n",
    "for itr in data_itr: #Iterate through the whole dataset, takes 1 batch at a time\n",
    "    images, labels = itr #Stores images and the corresponding labels in images and labels\n",
    "    print(\"Size of images\", images.shape)\n",
    "    print(\"Labels tensor = \", labels)\n",
    "    break #Sould be removed to iterate though whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T14:45:44.893116Z",
     "start_time": "2020-04-10T14:45:44.880112Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0.2314, 0.1686, 0.1961,  ..., 0.6196, 0.5961, 0.5804],\n",
      "          [0.0627, 0.0000, 0.0706,  ..., 0.4824, 0.4667, 0.4784],\n",
      "          [0.0980, 0.0627, 0.1922,  ..., 0.4627, 0.4706, 0.4275],\n",
      "          ...,\n",
      "          [0.8157, 0.7882, 0.7765,  ..., 0.6275, 0.2196, 0.2078],\n",
      "          [0.7059, 0.6784, 0.7294,  ..., 0.7216, 0.3804, 0.3255],\n",
      "          [0.6941, 0.6588, 0.7020,  ..., 0.8471, 0.5922, 0.4824]],\n",
      "\n",
      "         [[0.2431, 0.1804, 0.1882,  ..., 0.5176, 0.4902, 0.4863],\n",
      "          [0.0784, 0.0000, 0.0314,  ..., 0.3451, 0.3255, 0.3412],\n",
      "          [0.0941, 0.0275, 0.1059,  ..., 0.3294, 0.3294, 0.2863],\n",
      "          ...,\n",
      "          [0.6667, 0.6000, 0.6314,  ..., 0.5216, 0.1216, 0.1333],\n",
      "          [0.5451, 0.4824, 0.5647,  ..., 0.5804, 0.2431, 0.2078],\n",
      "          [0.5647, 0.5059, 0.5569,  ..., 0.7216, 0.4627, 0.3608]],\n",
      "\n",
      "         [[0.2471, 0.1765, 0.1686,  ..., 0.4235, 0.4000, 0.4039],\n",
      "          [0.0784, 0.0000, 0.0000,  ..., 0.2157, 0.1961, 0.2235],\n",
      "          [0.0824, 0.0000, 0.0314,  ..., 0.1961, 0.1961, 0.1647],\n",
      "          ...,\n",
      "          [0.3765, 0.1333, 0.1020,  ..., 0.2745, 0.0275, 0.0784],\n",
      "          [0.3765, 0.1647, 0.1176,  ..., 0.3686, 0.1333, 0.1333],\n",
      "          [0.4549, 0.3686, 0.3412,  ..., 0.5490, 0.3294, 0.2824]]]]), tensor([6])]\n"
     ]
    }
   ],
   "source": [
    "for data in trainCFAR10Loader:\n",
    "    print(data) #Prints the first batch\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T15:10:41.027755Z",
     "start_time": "2020-04-10T15:10:41.024274Z"
    }
   },
   "source": [
    "## Changing the batch_size and shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T18:49:16.058742Z",
     "start_time": "2020-04-10T18:49:16.052603Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of images torch.Size([8, 3, 32, 32])\n",
      "Labels tensor =  tensor([1, 7, 8, 0, 1, 4, 0, 3])\n"
     ]
    }
   ],
   "source": [
    "trainCFAR10Loader = torch.utils.data.DataLoader(trainCFAR10, batch_size=8, shuffle=True)\n",
    "data_itr = iter(trainCFAR10Loader)\n",
    "images, labels = data_itr.next()\n",
    "print(\"Size of images\", images.shape) #8 - batch size, 3 - no of chanells, last two dimensions - height and width of images\n",
    "print(\"Labels tensor = \", labels) #8 labels since the batch_size is 8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "374.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
