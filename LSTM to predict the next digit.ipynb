{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries and functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T07:43:17.926190Z",
     "start_time": "2020-05-09T07:43:17.659331Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd.variable import Variable\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T07:43:17.931224Z",
     "start_time": "2020-05-09T07:43:17.927751Z"
    }
   },
   "outputs": [],
   "source": [
    "def underlined_text(text, char = '='):\n",
    "    length = len(text)\n",
    "    print(text)\n",
    "    for i in range(length):\n",
    "        print(char, end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T07:43:19.522785Z",
     "start_time": "2020-05-09T07:43:17.933086Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X\n",
      "=\n",
      "Shape =  torch.Size([10, 1])\n",
      "tensor([[0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4],\n",
      "        [5],\n",
      "        [6],\n",
      "        [7],\n",
      "        [8],\n",
      "        [9]], device='cuda:0')\n",
      "\n",
      "y\n",
      "=\n",
      "torch.Size([10])\n",
      "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 0], device='cuda:0')\n",
      "\n",
      "Sequence order: (Input => Output)\n",
      "=================================\n",
      "0 => 1\n",
      "1 => 2\n",
      "2 => 3\n",
      "3 => 4\n",
      "4 => 5\n",
      "5 => 6\n",
      "6 => 7\n",
      "7 => 8\n",
      "8 => 9\n",
      "9 => 0\n"
     ]
    }
   ],
   "source": [
    "underlined_text(\"X\")\n",
    "X = torch.tensor([[i] for i in range(0,10)]).to(device)\n",
    "print(\"Shape = \", X.shape)\n",
    "print(X)\n",
    "print()\n",
    "underlined_text(\"y\")\n",
    "y = torch.tensor([i for i in range(1,10)])\n",
    "z = torch.tensor([0])\n",
    "y = torch.cat((y, z), dim=0).to(device)\n",
    "print(y.shape)\n",
    "print(y)\n",
    "print()\n",
    "underlined_text(\"Sequence order: (Input => Output)\")\n",
    "for i in range(len(X)):\n",
    "    print(X[i].item(), '=>', y[i].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping dataX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshaping the dataX into a format [batch_size, seq_len, no_features]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T07:43:19.527982Z",
     "start_time": "2020-05-09T07:43:19.523915Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped X\n",
      "==========\n",
      "torch.Size([10, 1, 1])\n",
      "tensor([[[0]],\n",
      "\n",
      "        [[1]],\n",
      "\n",
      "        [[2]],\n",
      "\n",
      "        [[3]],\n",
      "\n",
      "        [[4]],\n",
      "\n",
      "        [[5]],\n",
      "\n",
      "        [[6]],\n",
      "\n",
      "        [[7]],\n",
      "\n",
      "        [[8]],\n",
      "\n",
      "        [[9]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "underlined_text(\"Reshaped X\")\n",
    "X = X.view(X.shape[0], 1, 1) # [batch_size, seq_len, features]\n",
    "print(X.shape)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T07:43:19.545016Z",
     "start_time": "2020-05-09T07:43:19.528844Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing X\n",
      "=============\n",
      "torch.Size([10, 1, 1])\n",
      "tensor([[[0.0000]],\n",
      "\n",
      "        [[0.1000]],\n",
      "\n",
      "        [[0.2000]],\n",
      "\n",
      "        [[0.3000]],\n",
      "\n",
      "        [[0.4000]],\n",
      "\n",
      "        [[0.5000]],\n",
      "\n",
      "        [[0.6000]],\n",
      "\n",
      "        [[0.7000]],\n",
      "\n",
      "        [[0.8000]],\n",
      "\n",
      "        [[0.9000]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "underlined_text(\"Normalizing X\")\n",
    "X = X/float(X.shape[0])\n",
    "print(X.shape)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the default mode (i.e. batch_first = False), the input shape should have the shape [seq_len, batch_size, \n",
    "features]. If you want the input shape should be of the shape [batch_size, seq_len, features], set batch_first = True.\n",
    "\n",
    "seq_len - Number of time steps in each input stream\n",
    "<br>\n",
    "features - Number of input features per time-step\n",
    "<br>\n",
    "batch_size - Size of the batches (sample size)\n",
    "<br>\n",
    "hidden_size - Number of RNN/LSTM blocks\n",
    "<br>\n",
    "num_layers - Number of hidden layers (default = 1)\n",
    "<br>\n",
    "<br>\n",
    "<u>Input shapes</u>\n",
    "<br>\n",
    "Input's shape = [seq_len, batch_size, features] if batch_first = False\n",
    "<br>\n",
    "Input's shape = [batch_size, seq_len, features] if batch_first = True\n",
    "<br>\n",
    "Initial hidden layer's shape = [num_layers, batch_size, hidden_size]\n",
    "<br>\n",
    "<br>\n",
    "<u>Hidden layer's shape</u>\n",
    "<br>\n",
    "[num_layers, batch_size, hidden_size]\n",
    "<br>\n",
    "\n",
    "<u>Output shape</u>\n",
    "<br>\n",
    "Hidden layer's shape = [num_layers, batch_size, hidden_size] (Since in an RNN, hidden state also returned as an output)\n",
    "<br>\n",
    "Output's shape = [seq_len, batch_size, hidden_size] if batch_first = False\n",
    "<br>\n",
    "Output's shape = [batch_size, seq_len, hidden_size] if batch_first = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTMDigit clsss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T07:43:19.749376Z",
     "start_time": "2020-05-09T07:43:19.546343Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMDigit(\n",
      "  (lstm_layer): LSTM(1, 16, batch_first=True)\n",
      "  (linear_layer): Linear(in_features=16, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class LSTMDigit(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, batch_size, num_layers, output_size):\n",
    "        super(LSTMDigit, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.lstm_layer = nn.LSTM(input_size=self.input_size, hidden_size=self.hidden_size,\n",
    "                               num_layers=self.num_layers, batch_first=True)\n",
    "        \n",
    "        self.linear_layer = nn.Linear(in_features=self.hidden_size, out_features=10)\n",
    "        \n",
    "        self.hidden = self.init_hidden() # Initializing the hidden state\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        # Initialize the hidden states\n",
    "        h0 = torch.randn(self.num_layers, self.batch_size, self.hidden_size).to(device)\n",
    "        c0 = torch.randn(self.num_layers, self.batch_size, self.hidden_size).to(device)\n",
    "        return (h0, c0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        lstm_out, self.hidden = self.lstm_layer(x, self.hidden)\n",
    "        reshaped_lstm_out = lstm_out.view(self.batch_size, self.hidden_size)\n",
    "        final_out = self.linear_layer(reshaped_lstm_out)\n",
    "        return final_out\n",
    "        \n",
    "lstm = LSTMDigit(input_size=1, hidden_size=16, batch_size=10, num_layers=1, output_size=10).to(device)\n",
    "print(lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T07:43:19.752489Z",
     "start_time": "2020-05-09T07:43:19.750343Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(lstm.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T07:43:19.758439Z",
     "start_time": "2020-05-09T07:43:19.754211Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_eval(preds, outputs):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    \n",
    "    max_vals, pred_class = torch.max(preds, dim=1)\n",
    "    for i in range(10):\n",
    "        if (pred_class[i]==outputs[i]):\n",
    "            correct += 1\n",
    "    acc = (correct/10.0)*100.0\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the loss.backward() function, the parameter 'retain_graph' needs to be set as 'True', since part of the computational graph will be freed during the execution of the loop. This is not needed in most cases, however, in an RNN, previous hidden states are passed to RNN cells, hence it needs the full graph to calculate the derivatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T07:43:51.744884Z",
     "start_time": "2020-05-09T07:43:19.759617Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loop\n",
      "=============\n",
      "Epoch:   100/ 500 ==> Loss:  2.1902,  Accuracy:  20.00\n",
      "Epoch:   200/ 500 ==> Loss:  1.8156,  Accuracy:  30.00\n",
      "Epoch:   300/ 500 ==> Loss:  1.7398,  Accuracy:  40.00\n",
      "Epoch:   400/ 500 ==> Loss:  1.7166,  Accuracy:  40.00\n",
      "Epoch:   500/ 500 ==> Loss:  1.7039,  Accuracy:  30.00\n"
     ]
    }
   ],
   "source": [
    "underlined_text(\"Training loop\")\n",
    "epochs = 500\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = lstm(X)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    accuracy = model_eval(y_pred, y)\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    if ((epoch+1)%100 == 0):\n",
    "        print(\"Epoch: \", \"{:4d}/{:4d} ==>\".format(epoch+1,epochs), \n",
    "              \"Loss: \", \"{:6.4f}, \".format(loss.item()), \"Accuracy: \", \"{:4.2f}\".format(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "374.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
