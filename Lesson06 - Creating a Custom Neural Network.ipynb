{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import torch.nn as nn #For neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a custom neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class custom_nn (nn.Module):\n",
    "    def __init__(self, n_inputs, n_hidden_neurons, n_outputs):\n",
    "        super(custom_nn, self).__init__()\n",
    "        self.model = nn.Sequential(nn.Linear(n_inputs, n_hidden_neurons),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(n_hidden_neurons, n_outputs),\n",
    "                                   nn.Tanh()\n",
    "                                   )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 10])\n",
      "torch.Size([15, 10])\n",
      "Wait - training the model\n",
      "Epoch :  10000 Loss =  0.231475368142128\n",
      "Epoch :  20000 Loss =  0.2016017884016037\n",
      "Epoch :  30000 Loss =  0.19060766696929932\n",
      "Epoch :  40000 Loss =  0.18365898728370667\n",
      "Epoch :  50000 Loss =  0.17885242402553558\n",
      "Epoch :  60000 Loss =  0.17546415328979492\n",
      "Epoch :  70000 Loss =  0.17297407984733582\n",
      "Epoch :  80000 Loss =  0.17093497514724731\n",
      "Epoch :  90000 Loss =  0.1693805754184723\n",
      "Epoch :  100000 Loss =  0.16825567185878754\n",
      "Loss =  0.16825567185878754\n",
      "CPU times: user 2min 39s, sys: 3.03 s, total: 2min 42s\n",
      "Wall time: 27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ninputs = 10 #No of inputs\n",
    "nhidden = 5 #No of hidden neurons\n",
    "noutputs = 10 #No of outputs\n",
    "nexamples = 15 #No of examples to given to the neural network\n",
    "\n",
    "x = t.randn(nexamples, ninputs)\n",
    "y = x #Output is same as input - an autoencoder\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "  \n",
    "nnCPU = custom_nn(ninputs, nhidden, noutputs) #Create an object (nn1) of custom_nn class\n",
    "\n",
    "loss_fn = nn.MSELoss() #Loss function\n",
    "optimizer = t.optim.SGD(nnCPU.parameters(), lr = 0.01) #Defining the optimizer - SGD\n",
    "epochs = 100000\n",
    "\n",
    "print(\"Wait - training the model\")\n",
    "#Gradient Descent Algorithm\n",
    "for i in range(epochs):\n",
    "    ypred = nnCPU(x) #Calculate predicted value of the model\n",
    "    loss = loss_fn(ypred, y) #Apply the loss function (MSE) to calculate MSE\n",
    "    if ((i+1) % 10000 == 0):\n",
    "        print(\"Epoch : \", i+1, \"Loss = \", loss.item()) #Prints loss after each 10,000 epochs\n",
    "    loss.backward() #Backward - Backward propagation\n",
    "    optimizer.step() #Update all parameters\n",
    "    optimizer.zero_grad() #Set gradients of all parameters to zero before starting the next epoch\n",
    "    \n",
    "print(\"Loss = \", loss.item()) #Prints the final loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting output for unseen inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_new =  tensor([[-0.4134, -0.5242, -0.8779, -0.2582,  0.1580,  0.8885, -1.2871, -0.5490,\n",
      "          0.2534,  0.1095]])\n",
      "y_new =  tensor([[-0.9356,  0.0761, -1.0000,  0.9911,  0.8794, -0.8312, -0.9758, -0.9239,\n",
      "          0.6623, -0.0621]], grad_fn=<TanhBackward>)\n"
     ]
    }
   ],
   "source": [
    "x_new = t.randn(1, ninputs) #New inputs\n",
    "y_new = nnCPU(x_new) #Predicting outputs using the trained model\n",
    "print(\"x_new = \", x_new)\n",
    "print(\"y_new = \", y_new) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the neural network and data on a GPU if it is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU =  cuda:0\n",
      "torch.Size([15, 10])\n",
      "torch.Size([15, 10])\n",
      "Wait - training the model\n",
      "Epoch :  10000 Loss =  0.23078830540180206\n",
      "Epoch :  20000 Loss =  0.2047799676656723\n",
      "Epoch :  30000 Loss =  0.19573847949504852\n",
      "Epoch :  40000 Loss =  0.19138577580451965\n",
      "Epoch :  50000 Loss =  0.1889788806438446\n",
      "Epoch :  60000 Loss =  0.18722932040691376\n",
      "Epoch :  70000 Loss =  0.18587522208690643\n",
      "Epoch :  80000 Loss =  0.18514207005500793\n",
      "Epoch :  90000 Loss =  0.18463115394115448\n",
      "Epoch :  100000 Loss =  0.18409566581249237\n",
      "Loss =  0.18409566581249237\n",
      "CPU times: user 50.9 s, sys: 1.36 s, total: 52.2 s\n",
      "Wall time: 52.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if t.cuda.is_available():\n",
    "    device = t.device(\"cuda:0\") #If a GPU is availble, set device as first GPU (0 means first GPU)\n",
    "    print(\"Running on the GPU = \", device)\n",
    "else:\n",
    "    device = t.device(\"cpu\") #Else set the device as CPU\n",
    "    print(\"Running on the CPU = \", device)\n",
    "\n",
    "ninputs = 10 #No of inputs\n",
    "nhidden = 5 #No of hidden neurons\n",
    "noutputs = 10 #No of outputs\n",
    "nexamples = 15 #No of examples to given to the neural network\n",
    "\n",
    "x = t.randn(nexamples, ninputs, device=device)   #IMPORTANT - x is now on GPU if a GPU is available\n",
    "y = x #Output is same as input - an autoencoder  #IMPORTANT - y too is now on GPU if a GPU is available\n",
    "\n",
    "#IMPORTANT - be cautious if data is too large and if GPU memory is not fit enough for the data \n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "  \n",
    "nnGPU = custom_nn(ninputs, nhidden, noutputs) #Create an object (nn1) of custom_nn class\n",
    "nnGPU = nnGPU.to(device) #IMPORTANT - Neural network nn1 is passed to GPU if a GPU is available\n",
    "\n",
    "loss_fn = nn.MSELoss() #Loss function\n",
    "optimizer = t.optim.SGD(nnGPU.parameters(), lr = 0.01) #Defining the optimizer - SGD\n",
    "epochs = 100000\n",
    "\n",
    "print(\"Wait - training the model\")\n",
    "#Gradient Descent Algorithm\n",
    "for i in range(epochs):\n",
    "    ypred = nnGPU(x) #Calculate predicted value of the model\n",
    "    loss = loss_fn(ypred, y) #Apply the loss function (MSE) to calculate MSE\n",
    "    if ((i+1) % 10000 == 0):\n",
    "        print(\"Epoch : \", i+1, \"Loss = \", loss.item()) #Prints loss after each 10,000 epochs\n",
    "    loss.backward() #Backward - Backward propagation\n",
    "    optimizer.step() #Update all parameters\n",
    "    optimizer.zero_grad() #Set gradients of all parameters to zero before starting the next epoch\n",
    "    \n",
    "print(\"Loss = \", loss.item()) #Prints the final loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting output for unseen inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_new =  tensor([[-1.4502,  0.7624,  0.0699, -0.2669,  1.1746,  1.1821,  0.9249,  0.1458,\n",
      "          0.2466, -0.8550]])\n",
      "y_new =  tensor([[-0.9316,  0.9683, -0.4776, -0.9994,  0.9971, -0.9475, -0.0310,  0.4689,\n",
      "          0.9862, -1.0000]], grad_fn=<TanhBackward>)\n"
     ]
    }
   ],
   "source": [
    "x_new = t.randn(1, ninputs) #New inputs\n",
    "nnGPU = nnGPU.to(\"cpu\") #IMPORTANT - nnGPU transfered back to the CPU as x_new is on CPU\n",
    "y_new = nnGPU(x_new) #Predicting outputs using the trained model\n",
    "print(\"x_new = \", x_new)\n",
    "print(\"y_new = \", y_new) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
